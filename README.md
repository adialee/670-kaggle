Our approach started by cleaning the text with a custom TextCleaner transformer, which converted all text to lowercase and replaced numbers with a <NUM> token to remove unnecessary variation. We then built a FeatureUnion that combined two TfidfVectorizer components: a word-level vectorizer using 1–3 word n-grams to capture meaning and context, and a character-level vectorizer using 3–5 character n-grams to pick up stylistic and structural patterns often seen in machine-generated text. These features were fed into a LinearSVC classifier, chosen for its strength with high-dimensional sparse text data, and wrapped in CalibratedClassifierCV to produce probability estimates and allow us to optimize the decision threshold for F1 score. We trained this pipeline on a random sample of 100,000 rows from the training data, validated performance on the validation set, and finally used the trained pipeline to generate predictions for the test set
